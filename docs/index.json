[
{
	"uri": "https://covesa.github.io/cdsp/overview/",
	"title": "Playground overview",
	"tags": [],
	"description": "",
	"content": "Introduction Learn the basics and benefits of using the playground\n"
},
{
	"uri": "https://covesa.github.io/cdsp/overview/cdsp-overview/",
	"title": "Playground overview",
	"tags": [],
	"description": "",
	"content": "The Central Data Service Playground (CDSP) serves as a neutral, open playground for data services both within and outside the vehicle in the context of data-centric architectures. It enables investigation into the internals of these services and how they can be combined. Furthermore, the playground provides a means to publish and collaborate on such work in the open.\nThe playground was first conceived by the COVESA Data Architecture team to meet their needs. They also recognized that there were the same needs in the wider community inside and outside COVESA. For example, to demonstrate how VSS data can be used with its eco-system for newcomers.\nNext steps:\nLogical concept Implementation concept COVESA eco-system and beyond "
},
{
	"uri": "https://covesa.github.io/cdsp/manuals/",
	"title": "Manuals",
	"tags": [],
	"description": "",
	"content": "Introduction This section contains user guides and reference manuals for the playground\n"
},
{
	"uri": "https://covesa.github.io/cdsp/overview/cdsp-logical-concept/",
	"title": "Playground logical concept",
	"tags": [],
	"description": "",
	"content": "Importance of maintaining a logical concept COVESA is a grass roots OSS automotive alliance. From a communication and community perspective it is important to maintain descriptions of the logical concepts. Discussion at a logical level allows different parties to collaborate on common concepts, whilst making different implementation decisions, e.g. in product/technology selection or system architecture for example. That however does not mean we need spend months in philosophical discussions before moving to implementation. Instead logical concepts (why, what) can be developed alongside implementation.\nThe Data Architecture team therefore intends to maintain concepts for both logical and implementation alongside each other for their projects using the playground.\nOf course it is perfectly normal that in using the playground to develop an idea, example or pattern, that an architecture and components are chosen as part of the design.\nWhy Central Data Service Playground ? Problem OEMs have presented various open questions and requirements in tackling growing software complexity. One representative list appears below.\n\u0026ldquo;Key questions for a End-to-End Data Architecture:\nHow data can be shared between all touchpoints? How different domains of data share same tech stack? How should a bidirectional sync work? Who is responsible for conflict management? Who takes care about permissions, roles, rights and privacy? How the data model can be updated and synced? How subscriptions can be handled? How to handle historized and time series data \u0026hellip; \u0026hellip;on different touchpoints? How to handle multiple sync endpoints? How to handle unidirectional data streams? How (new) knowledge \u0026hellip; \u0026hellip; can be shared with others?\u0026rdquo; Source: \u0026ldquo;Building Bridges with a common Data Middleware\u0026rdquo;, OEM, COVESA Autumn 2023 AMM\nAt the same time there has been a realization that some problems require open collaboration.\nGoal The playground was first conceived by the COVESA Data Architecture team to meet their needs in addressing these problems. They also recognized similar needs in the wider community inside and outside COVESA. For example, for COVESA to demonstrate how VSS data can be used with its eco-system for newcomers.\nThe playground goals from the introductory overview:\nThe Central Data Service Playground (CDSP) serves as a neutral, open playground for data services both within and outside the vehicle in the context of data-centric architectures. It enables investigation into the internals of these services and how they can be combined. Furthermore, the playground provides a means to publish and collaborate on such work in the open.\nThe following sections address the Why, What and How in more detail.\nWhy Central Data Service? VSS is a mechanism of abstraction. The COVESA logical architecture for the VSS eco-system shown below places operation in the \u0026lsquo;big ECUs\u0026rsquo;, in zonal ECUs and above. Discussion of next-gen and data-centric architectures suggests investigation into data services in zone, domain and HPC controller scenarios and the cooperation between them. Hence Central. The COVESA Logical Architecture A repeating pattern of discussion in the COVESA Data Architecture team is the combination of VSS Data Server and VSS Data Store with advanced features and their connection southbound to feeders/native data and northbound to clients and off-board. Hence Data Service.\nThe name Central Data Service is not an attempt to introduce a new category of component. It is used here simply as a useful synonym for what otherwise would be a longer descriptive phrase explaining combinations of VSS centric Data Server and Store and their location in the vehicle.\nWhy Playground? Why not PoC? A PoC is often a snapshot in time and often specific in scope. Playground suggests greater flexibility. The central service, the Lego building block, is intended to be flexible and evolving. Similarly with what it is combined with to illustrate COVESA concepts and technology.\nThe Playground could certainly be used to implement a PoC.\nPatterns such as view/controller, out of the box data servers, data stores linked to applications (e.g. SQLite) etc are well known. The Service could in part be defined by what\u0026rsquo;s not known, by open questions in next-gen architectures such as data-centric architectures, that needs to be tackled down. The Playground is the means to doing that and illustrating the results.\nWhat? Requirements The data service core requirements At its core the service has requirements in three key areas:\nData Models: the live data models - VSS as the abstracted view of the vehicle, along with other adjacent data models such as personal data.\nPersistence: history of the model and signals etc - historical and cached timeseries data.\nApplication logic / APIs: standardized APIs for accessing the data such as the Vehicle Information Service Specification (VISS) or GraphQL.\nAdditional requirements: It is recognized that additional features, such as synchronization are absolutely desirable and have been a part of discussions in the Data Architecture team. Such features may also already be part of the feature set of the playground components. For example, both the Apache IoTDB and MongoDB Realm databases have sync capabilities. A base feature set is described as a starting point to help readers quickly grasp the concept. Additional features will be created or illustrated collectively based on interest and participation.\nComponents As a starting point the playground has been realized as a \u0026lsquo;project of projects\u0026rsquo; to create the basic building block data service. Achieved by combining a VISS Data Protocol Server with highly functional VSS Data Stores.\nThe VISS Protocol Server principally provides northbound get/set/sub application logic using the VISS protocol. Along with the secondary benefit of any additional features provided by the server.\n\u0026lsquo;Highly functional\u0026rsquo; in the context of the VSS Data Store means the flexible means to store, query, process and analysis timeseries data. An archetype would be a database server that can operate in-vehicle and the cloud. Such a component provides the possibility of using a variety of different architecture patterns, such as both client-server and event-driven, or data processing approaches.\nFlexibility in use As well as the mentioned flexibility in implementation, flexibility in use is also intended:\nWith some supporting documentation it can help meet the ongoing request from newcomers to the VSS eco-system as to how VSS can be used.\nThe Data Architecture group has various topics it wishes to investigate related to data-centric architectures. Data layer topics such as sync, data reduction and data quality. Also separation of concerns and cooperation between data and knowledge layers.\nThe playground can be used to investigate internals of data services. For example, connecting to medium and high speed data, or adding a protocol.\nExternal connections with other systems may also be a focus. For example, combining the service with other components to implement a particular touchpoint such as mobile.\nFurther details can be found in the following sections.\nThe Playground in context To help understand its use lets quickly place the playground in context.\nBig picture: As stated above the COVESA logical architecture places its scope at Zonal ECUs and above as shown in the diagram. It is assumed that the playground would likely be deployed on a Zone, Domain or Central controller, with corresponding h/w capabilities.\nInteraction between \u0026lsquo;Large ECU\u0026rsquo;: In the COVESA Data Architecture team it is recognized that zone/domain specific data services will need to synchronize and cooperate between themselves and/or with a central vehicle computer, e.g. Inter-controller sync/cooperation:\nSource: vss-otaku\nIn-vehicle southbound: The playground can be integrated southbound to lower parts of the vehicle and its native data, through data feeders and connectors. This can include making connections to other systems such as Autosar etc.\nNorthbound: connections will be made to clients, mobile, cloud and major in-vehicle domains such as IVI running Android/Apple etc.\nLogical domains: Connections may also be made to other logical data domains. For example, there is an knowledge layer proposal made in the COVESA Data Architecture team that discusses the separation of concerns and interaction between knowledge, information and raw data layers as illustrated below. The Playground here could be used to provide the data/information layer services in its investigation.\nSource: knowledge layer proposal\nProject success factors Newcomers to COVESA technology use the playground to accelerate their understanding of how the technology can be used. That could be a looking at a simple instance of how a VSS data server is combined with a VSS data store and queried using VISS. It could also be a more complex instance that combines components to illustrate a longer specific end to end use case, e.g. mobile to vehicle connection.\nInternal groups within COVESA naturally use the logical concepts and the playground implementation in combination with other components to develop and disseminate ideas. This especially applies to the Data Architecture and Infrastructure pillar.\nSupporting materials such as patterns, diagrams, cookbooks etc are adopted as useful assets within and outside COVESA, which in turn helps socialization.\nHow? Address two high level implementation needs, keeping in mind a path towards production where possible:\nEasy to develop: make it easy to build, modify and trial by providing an instance running on a host, e.g. using Docker container(s).\nCloser to production: the same base code should be deployable to systems closer to production, including on automotive hardware (or its simulation), e.g. Yocto, container orchestration, SOA etc.\nA path towards production can be supported by using production components, rather than overly simple substitutes, where it makes sense. For instance a particular scenario may use Kafka in a cloud connection. The point is not to pick a winning product in a particular category, but to recognize that using a production tool can represent a category that is known to scale. Detailed requirements for a specific production project and product selection for it, is rightly left to that project.\nA generic code base for the basic building blocks should allow flexible compilation to meet those needs on multiple architectures, e.g. x86, ARM and RISC-V. The target for how it is used being a matter of deployment at a high level.\nFollow the OSS mantra of adopt where you can, extend if needed, create where necessary.\nPromote flexible reconfiguration of components by favouring loose coupling over tight coupling.\n"
},
{
	"uri": "https://covesa.github.io/cdsp/examples/",
	"title": "Playground examples",
	"tags": [],
	"description": "",
	"content": "Learn how to use the playground by stepping through examples.\nNote: There is not a separate section for the VSS data model because the vast majority of the examples will be making use of it.\nGetting started Docker sanity test | Hello-world\nData Layer, Processing and Analysis Data Reduction | Data Quality | Events | Data Streams etc.\nTip: well you wait for some examples consider how you could use the IoTDB data processing functions in the UDF library.\nKnowledge Layer, Reasoning and Data Models Data Layer Connector | A | B | C etc.\nFeeders RemotiveLabs | WAII VISS | etc.\nCOVESA Touchpoints A | B | C\nCOVESA Technologies vsome/ip (SOME/IP) | uServices | Vehicle API | VISS etc.\nDatabases Apache IoTDB | MongoDB Realm | Redis/SQLite/memcache etc.\nFrameworks / Protocols vsome/ip (SOME/IP) | VISS | uServices/uProtocol/Capabilities | Vehicle API | MQTT | Kafka | Apache Zeppelin etc.\nBig data Hadoop | Flink | Spark | Cloud DB | Nifi etc.\nOther examples A | B | C\n"
},
{
	"uri": "https://covesa.github.io/cdsp/overview/cdsp-implementation-concept/",
	"title": "Playground implementation",
	"tags": [],
	"description": "",
	"content": "The prior section describing the logical concept should be read to understand the concepts to be implemented.\nAs outlined in the logical description, as a starting point the Service is realized as a basic building block combining VISS Data Server with highly functional (VSS) Data Store.\nVISS data server The reference implementation for the COVESA VISS specification is developed in the VISSR project. The playground has included VISSR to provide its northbound VISS support.\nAlongside the VISS server the VISSR project provides clients, feeders and tooling. Further details can be found in the upstream VISSR documentation site.\nDuring initial development of the playground the upstream VISSR project supported using SQLite, Redis or memcached databases as its data store.\nHighly functional (VSS) data store As explained earlier in the logical concept the playground includes the use of highly functional VSS data stores to expand the available data processing possibilities. Two archetypes were considered:\nDatabase server with timeseries capabilities Application database The OSS Apache IoTDB project was selected for the database server archetype for reasons explained in the section below.\nTo enable access to VSS data stored in IoTDB using the VISS protocol the playground project extended VISSR to support IoTDB as one of its supported data store backends. That support was upstreamed and merged.\nFor the application database archetype MongoDB Realm was selected. Support for it is currently a work in progress as part of the playground project backlog.\nApache IoTDB The Apache IoTDB project page describes IoTDB as:\n\u0026ldquo;Apache IoTDB (Database for Internet of Things) is an IoT native database with high performance for data management and analysis, deployable on the edge and the cloud. Due to its light-weight architecture, high performance and rich feature set together with its deep integration with Apache Hadoop, Spark and Flink, Apache IoTDB can meet the requirements of massive data storage, high-speed data ingestion and complex data analysis in the IoT industrial fields.\u0026rdquo;\nThe diagram below summarizes some of the features that make it an attractive addition to the playground.\nSummary of Apache IoTDB features The focus on timeseries IoT data delivering high throughput, with low latency are a good fit with the automotive domain. The availability of a single node (Edge) server build is critical for in-vehicle investigations and is supported by the existence of a cluster build for the cloud if needed.\nIts support for client server, event and streaming data architectures allows for flexible operation using a single solution.\nIt also has very wide API support that greatly enhances the pluggability of the data store into other components, whilst supporting the playground project goal of loose coupling.\nSimilarly the wide range of integrations into other tools and frameworks, particularly the Apache big data stack, simplifies the integration of VSS and associated data into data-centric workflows.\nIoTDB has a wide range of built-in timeseries data processing and analysis functions covering topics such as data quality, profiling, repair, anomaly detection and series discovery. For example, in-vehicle data analysis can be performed to derive some information or knowledge and then data reduced for further processing in the cloud.\nAs well as Native APIs IoTDB also supports a SQL-like query language. This supports the describing of work in logical terms that affords some portability to other solutions.\nDeployment The project is currently targeting two deployment scenarios:\nEasy to develop: make it easy to build, modify and trial by providing a containerized instance running on a host using Docker containers. Closer to production: the same base code should be deployable to systems closer to production, including on automotive hardware (or its simulation), e.g. Yocto, container orchestration, Service-orientated architecture (SOA) etc. Docker containers are chosen to facilitate the rapid integration and/or swapping of technology options. Be it internals of the playground itself, or connection to other components. For example, users can easily integrate the playground into their own docker compose containing other components.\nStatus The containerized docker deployment is available. Deployment on automotive hardware is currently not but is part of the project backlog.\nHost based Docker The playground provides docker compose files to deploy the playground using docker images. The deployment contains three main services, for Apache IoTDB, VISSR and Redis.\nPlease see the playground docker readme.md in the source tree for details.\nThe service definitions are based on the upstream compose files from the IoTDB and VISSR projects.\nAutomotive hardware The project will provide information as hardware deployment progresses.\n"
},
{
	"uri": "https://covesa.github.io/cdsp/overview/covesa-and-beyond/",
	"title": "Combining with wider eco-system",
	"tags": [],
	"description": "",
	"content": "\u0026lt;TBA: This page will put the playground \u0026rsquo;lego piece\u0026rsquo; in context with the wider COVESA eco-system and beyond, e.g. connection to CVI/Capabilities/Vehicle API gateway southbound\u0026gt;\n"
},
{
	"uri": "https://covesa.github.io/cdsp/manuals/apache-iotdb/",
	"title": "Apache IoTDB",
	"tags": [],
	"description": "",
	"content": "Introduction The playground uses Apache IoTDB to provide a highly functional data store.\nDescription of Apache IoTDB from https://iotdb.apache.org/:\n\u0026ldquo;Apache IoTDB (Database for Internet of Things) is an IoT native database with high performance for data management and analysis, deployable on the edge and the cloud. Due to its light-weight architecture, high performance and rich feature set together with its deep integration with Apache Hadoop, Spark and Flink, Apache IoTDB can meet the requirements of massive data storage, high-speed data ingestion and complex data analysis in the IoT industrial fields.\u0026rdquo;\nThe IoTDB project website has extensive documentation on the IoTDB server. In the guide below we focus on topics specific to the playground such as VSS data schemas and the connector for the VISSR VISS data server.\nInfo: The intention is to add more information such as a guide for feeder integration as the project progresses.\nIntegrating VSS data into the IoTDB data model The \u0026ldquo;Basic Concept\u0026rdquo; section of the IoTDB documentation introduces the IoTDB data model, data types, encoding and compression.\nIn IoTDB terminology measurement is the key in a key/value pair. In VSS terms the leaf node name. The timeseries is the record of the measurement on the time axis. A timeseries is a series of time/value data points.\nThe IoTDB data model supports hierarchical partitioning and like VSS uses a dot notation to separate the levels. This means if we simply appended a VSS leaf node name like Vehicle.CurrentLocation.Longitude as the measurement (key) name to the end of a IoTDB path such as root.test2.dev1 the Vehicle.CurrentLocation. IoTDB would treat it as part of the IoTDB data model partitioning which could cause unwanted issues when scaling over millions of vehicles.\nWe have separated those two concepts by quoting the VSS leaf node name using backticks when processing the name in IoTDB. As shown below:\n\u0026lt;IoTDB prefix path\u0026gt;.`\u0026lt;VSS leaf node name\u0026gt;` In our example the full IoTDB measurement path would become root.test2.dev1.`Vehicle.CurrentLocation.Longitude` and in an IoTDB timeseries would look like this:\n+------------------------+---------------------------------------------------+ | Time|root.test2.dev1.`Vehicle.CurrentLocation.Longitude`| +------------------------+---------------------------------------------------+ |2024-03-07T17:55:24.514Z| -42.4567| |2024-04-10T17:48:12.117Z| -41.3567| |2024-04-10T17:48:23.389Z| -39.3567| |2024-04-10T17:48:49.630Z| -40.2578| +------------------------+---------------------------------------------------+ Seeding the database with VSS data To illustrate the concepts lets seed a database with some simple timeseries VSS data.\nThe typical steps are:\nCreate the database in the server. Create a timeseries in the database populated with the VSS leaf nodes (keys) you are interested in. Load the VSS data into the timeseries. Note: IoTDB has data type detection so creating a schema for the timeseries in step 2 is optional. However, the use of a schema has performance and meta-data benefits so is recommended.\nIoTDB has a very extensive collection of integrations, tools, clients and APIs that could be used to achieve this.\nExample using the IoTDB CLI client The following tutorial shows an example using the IoTDB CLI client, using two methods. Firstly, in interactive mode where you type the commands and then sending the same commands in batch command mode.\nConnect to the CLI client from your host: $ bash \u0026lt;iotdb path\u0026gt;/sbin/start-cli.sh -h \u0026lt;server hostname/ip\u0026gt; Create database from CLI command line: IoTDB \u0026gt; create database root.test2 Create timeseries from CLI command line: IoTDB \u0026gt; CREATE ALIGNED TIMESERIES root.test2.dev1(`Vehicle.CurrentLocation.Longitude` FLOAT, `Vehicle.CurrentLocation.Latitude` FLOAT, `Vehicle.Cabin.Infotainment.HMI.DistanceUnit` TEXT) Add some data into the timeseries: IoTDB\u0026gt; insert into root.test2.dev1(`Vehicle.CurrentLocation.Longitude`, `Vehicle.CurrentLocation.Latitude`, `Vehicle.Cabin.Infotainment.HMI.DistanceUnit`) values(-42.4567, 22.1234, \u0026#39;MILES\u0026#39;) Display the data just added as a sanity check: IoTDB\u0026gt; select last * from root.test2.dev1 +------------------------+-------------------------------------------------------------+--------+--------+ | Time| Timeseries| Value|DataType| +------------------------+-------------------------------------------------------------+--------+--------+ |2024-03-07T17:55:24.514Z| root.test2.dev1.`Vehicle.CurrentLocation.Longitude`|-42.4567| FLOAT| |2024-03-07T17:55:24.514Z|root.test2.dev1.`Vehicle.Cabin.Infotainment.HMI.DistanceUnit`| MILES| TEXT| |2024-03-07T17:55:24.514Z| root.test2.dev1.`Vehicle.CurrentLocation.Latitude`| 22.1234| FLOAT| +------------------------+-------------------------------------------------------------+--------+--------+ You have now seeded the database with some initial VSS data.\nThe CLI client startup script accepts SQL commands using the -e parameter. We can therefore use this to codify the above in a bash script. So the VSS node names (keys) are passed correctly on the command line the backticks must be escaped.\nFor example:\n# !/bin/bash host=127.0.0.1 rpcPort=6667 user=root pass=root bash ./sbin/start-cli.sh -h ${host} -p ${rpcPort} -u ${user} -pw ${pass} -e \u0026#34;create database root.test2\u0026#34; bash ./sbin/start-cli.sh -h ${host} -p ${rpcPort} -u ${user} -pw ${pass} -e \u0026#34;CREATE ALIGNED TIMESERIES root.test2.dev1(\\`Vehicle.CurrentLocation.Longitude\\` FLOAT, \\`Vehicle.CurrentLocation.Latitude\\` FLOAT, \\`Vehicle.Cabin.Infotainment.HMI.DistanceUnit\\` TEXT)\u0026#34; bash ./sbin/start-cli.sh -h ${host} -p ${rpcPort} -u ${user} -pw ${pass} -e \u0026#34;insert into root.test2.dev1(\\`Vehicle.CurrentLocation.Longitude\\`, \\`Vehicle.CurrentLocation.Latitude\\`, \\`Vehicle.Cabin.Infotainment.HMI.DistanceUnit\\`) values(-42.4567, 22.1234, \u0026#39;MILES\u0026#39;)\u0026#34; bash ./sbin/start-cli.sh -h ${host} -p ${rpcPort} -u ${user} -pw ${pass} -e \u0026#34;select last * from root.test2.dev1\u0026#34; Of course any of the programming language clients provided by IoTDB, e.g. go, python, C++, Rust, or integration into tools that support its SQL language, can also be used to achieve the same result.\nSingle node (Edge) vs Cluster The upstream IoTDB project has both standalone single node and cluster deployments, to cover use case requirements from edge to cloud.\nAt the time of writing the playground docker deployment deploys the single node IoTDB docker image, as it is most suitable for deployment at the edge in-vehicle, whilst still being able to represent the cloud.\nOf course if your cloud development requires higher performance then you can integrate the cluster version.\nUDF and UDF library for data processing Whilst IoTDB has a series of built-in timeseries processing functions you can add your own as User Defined Functions (UDF).\nThe UDF section of the IoTDB documentation explains how to develop and register your own.\nThe IoTDB project also maintains UDF Library an extensive collection of data processing functions covering:\nData Quality Data Profiling Anomaly Detection Frequency Domain Analysis Data Repair Series Discovery Machine Learning The UDF Library is an optional install. How to install the library is documented here. Documentation for the functions can be found here.\nThe combination of built-in and UDF library functions, built on the low latency queries enabled by IoTDB and its TsFile format gives you a lot to explore.\nVISSR (VISS) integration As part of the initial development of the playground the team extended VISSR to support connections to Apache IoTDB as a VISSR data store backend and upstreamed the support.\nConnector scope The support is implemented by connector code in the VISSR service manager, which connects VISSR to an external Apache IoTDB server. This code uses the IoTDB Go client to maintain a connection session to the IoTDB server, which it then uses to get/set vehicle data from the database.\nAs VISSR and the IoTDB server are separate processes VISSR needs to be told where to find the IoTDB server and which storage prefix to use to access the data.\nDevelopment followed the patterns set by the existing VISSR support for Redis and SQLite. The administration of the Apache IoTDB server itself, including startup and shutdown, is out of scope of the connector and is handled externally to VISSR. In the case of the playground this is handled by the playground compose.\nRuntime notes VISSR runtime assumptions:\nIoTDB server lifecycle (e.g. startup and shutdown) is handled externally to VISSR. Management (e.g. creation/deletion) of the IoTDB timeseries containing VSS data is handled externally to VISSR. Configuration of the connector code is specified in the config file iotdb-config.json. If the config file is not found then build-time defaults are used. Handling of IoTDB server and timeseries management is placed outside of VISSR to allow flexible deployment through loosely coupled connections.\nDatabase schema assumptions The connector assumes a simple key/value pair schema for accessing VSS data in an IoTDB timeseries:\nVSS node names (keys) are backtick quoted when stored as measurement keys in the database e.g. `Vehicle.CurrentLocation.Longitude`. This is for reasons explained above in \u0026ldquo;Integrating VSS data into the IoTDB data model\u0026rdquo; to avoid IoTDB interpreting the VSS tree path, in the example Vehicle.CurrentLocation., as part of its storage path which also uses a dot notation.\nVSS data is stored using native (IoTDB) data types rather than strings.\nThat the timeseries containing VSS nodes can be found using the prefix path specified in the config file.\nConfiguration The connection code reads its runtime configuration from the JSON formatted file iotdb-config.json located in the vissv2server directory. You must specify all values.\nConfiguration file format Key name Type Description host String Hostname or IP address of the IoTDB server port String RPC port of the server. Default is 6667 username String Username to access the server. Default is root password String Password to access the server. Default is root queryPrefixPath String Timeseries prefix path of VSS data in the database queryTimeout(ms) Int Query timeout in milliseconds Example iotdb-config.json:\n{ \u0026#34;host\u0026#34;: \u0026#34;iotdb-service\u0026#34;, \u0026#34;port\u0026#34;: \u0026#34;6667\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;queryPrefixPath\u0026#34;: \u0026#34;root.test2.dev1\u0026#34;, \u0026#34;queryTimeout(ms)\u0026#34;: 5000 } Logging The connector writes information, warning and error messages to the VISSR server log with the prefix IoTDB. Grepping in the log for that prefix string can help you quickly identify connector messages.\nVISSR Development notes Please see the notes in the VISSR source commit messages and related Github pull requests for the history of the development of the Apache IoTDB connection code and its integration into the VISSR Service Manager component.\nDevelopment followed the patterns set by the existing support for Redis and SQLite.\nThe connection code was first developed with Apache IoTDB v1.2.2, using the upstream standalone pre-built image and Apache IoTDB Go Client v1.1.7.\n"
},
{
	"uri": "https://covesa.github.io/cdsp/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://covesa.github.io/cdsp/",
	"title": "Central Data Service Playground",
	"tags": [],
	"description": "",
	"content": "Central Data Service Playground Overview Learn the basics and benefits of using the playground\nOverview\nBrowse by section Manuals This section contains user guides and reference manuals for the playground\nOverview | Apache IoTDB | VISSR | Integration guides | etc.\nExamples Learn how to use the playground by stepping through examples.\nOverview\n"
},
{
	"uri": "https://covesa.github.io/cdsp/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://covesa.github.io/cdsp/manuals/vissr-viss/",
	"title": "VISSR (VISS data server)",
	"tags": [],
	"description": "",
	"content": "Introduction The playground uses the VISSR project to provide its northbound VISS support, along with the other features it provides.\nThe VISSR project documentation site has extensive documentation on the VISSR components. So as the project progresses we will add information below focused on topics specific to the playground.\nApache IoTDB connector Please see the IoTDB guide for details of the connector between VISSR and IoTDB.\n"
}]